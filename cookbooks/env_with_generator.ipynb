{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with the Loong environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Loong *environment* is a unified interface that can be used for Synthetic Data Generation, RL training and Benchmarking agents. It integrates all the primitives that we implemented at CAMEL to provide a nice interface for developers and researchers. In this cookbook, we will explain how to initialize a *Single Step Environment* to generate synthetic data. More cookbooks about RL training and how to customize the environment are coming soon.\n",
    "\n",
    "This type of environment is called a *single step* environment, because the agent only does one step. It gets a question sampled from the dataset (the initial state / observation) and then answers. The answer is then scored according to the reward function. Recently, rules-based reward functions, i.e. functions without any learnable parameters, have been successfully used to do RL with LLMs as as policy.\n",
    "\n",
    "Since many RL algorithms (such as GRPO) need multiple rollouts at each step, batching is important to guarantee concurrency / parallelism. This notebook will show how to use batched environments.\n",
    "\n",
    "First, we have to load a dataset from which we will sample questions. The dataset can be either a `StaticDataset`, which is finite or it can be a `BaseGenerator`, which is an infinite supply of question - answer pairs, synthetically generated in some way, depending on the implementation. To seed the generative process of the `BaseGenerator`, we need to seed it with a *seed dataset*. Each generator uses the seed dataset it was initialized with to generate new data.\n",
    "\n",
    "In this cookbook, we will use the `FewShotGenerator`, which will generate new data points by doing simple few-shot prompting, using random data points from the seed dataset as examples.\n",
    "\n",
    "A seed dataset can easily be thought of as a type of `StaticDataset`, so let's initialize our seed dataset as such a `StaticDataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from camel.datasets import StaticDataset\n",
    "from camel.logger import get_logger\n",
    "\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "raw_data = [\n",
    "    {\n",
    "        \"question\": \"Evaluate the limit as x approaches 0 of (sin(3*x) - 3*x) / x**3.\",  # noqa: E501\n",
    "        \"final_answer\": \"-9/2\",\n",
    "        \"rationale\": '''from sympy import symbols, limit, sin\n",
    "x = symbols('x')\n",
    "expr = (sin(3*x) - 3*x) / x**3\n",
    "result = limit(expr, x, 0)\n",
    "print(result)''',\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Evaluate the definite integral of (1 - x**2)**3 from x = 0 to x = 1.\",  # noqa: E501\n",
    "        \"final_answer\": \"16/35\",\n",
    "        \"rationale\": '''from sympy import symbols, integrate\n",
    "x = symbols('x')\n",
    "expr = (1 - x**2)**3\n",
    "result = integrate(expr, (x, 0, 1))\n",
    "print(result)''',\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Evaluate the limit as n approaches infinity of n*(sqrt(n**2 + 1) - n).\",  # noqa: E501\n",
    "        \"final_answer\": \"1/2\",\n",
    "        \"rationale\": '''from sympy import symbols, limit, sqrt\n",
    "n = symbols('n', positive=True)\n",
    "expr = n*(sqrt(n**2 + 1) - n)\n",
    "result = limit(expr, n, float(\"inf\"))\n",
    "print(result)''',\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Compute the sum of the series sum from n = 1 to 50 of 1/(n*(n+1)).\",  # noqa: E501\n",
    "        \"final_answer\": \"50/51\",\n",
    "        \"rationale\": '''from sympy import symbols, summation\n",
    "n = symbols('n', positive=True, integer=True)\n",
    "expr = 1/(n*(n+1))\n",
    "result = summation(expr, (n, 1, 50))\n",
    "print(result)''',\n",
    "    },\n",
    "]\n",
    "\n",
    "seed_dataset = StaticDataset(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `FewShotGenerator` needs an python interpreter to compute a pseudo ground truth from the code it generated. For this, let's define a `PythonVerifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from camel.verifiers import PythonVerifier\n",
    "\n",
    "verifier = PythonVerifier(required_packages=[\"sympy\"])\n",
    "await verifier.setup(uv=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we need a model backend for the generation agent. Let's use the `ModelFactory` to create one.\n",
    "\n",
    "Note: We use GPT-4o mini as a default here, hence we load our OpenAI API key. Feel free to use other models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from camel.models import ModelFactory\n",
    "from camel.types import ModelPlatformType, ModelType\n",
    "from camel.configs import ChatGPTConfig\n",
    "from camel.datasets import FewShotGenerator\n",
    "\n",
    "model = ModelFactory.create(\n",
    "    model_platform=ModelPlatformType.OPENAI,\n",
    "    model_type=ModelType.GPT_4O_MINI,\n",
    "    model_config_dict=ChatGPTConfig().as_dict(),\n",
    ")\n",
    "\n",
    "# Note: When the generator needs to create new datapoints, it will by default create 20 new datapoints\n",
    "# Since we are paying for the API, let's set this number to 2 instead\n",
    "generator = FewShotGenerator(\n",
    "    puffer=2, seed_dataset=seed_dataset, verifier=verifier, model=model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our generator is all set up, let's create a `SingleStepEnv` with it.\n",
    "\n",
    "We also need to supply a verifier that checks for semantic equivalence between the response of the CoT agent (the one that we want to train with RL) and the synthetic answer.\n",
    "\n",
    "We can then call `env.reset()` to sample the underlying generator, which returns that question as an observation. We can then feed this observation into the CoT agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from camel.environments import Action, SingleStepEnv\n",
    "\n",
    "env = SingleStepEnv(generator, verifier)\n",
    "\n",
    "obs = await env.reset(seed=42)\n",
    "\n",
    "print(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The agent would then process this observation and select an action, which it would feed into the `step` function. For this, we will make use of an *extractor*. An extractor takes the LLM response and extracts the verifiable part out of it. Extractors can be initialized with different strategies which modifies the extraction behavior. We then compare it to our computed pseudo ground truth which we got internally by running the code in the rationale with the `PythonVerifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from camel.agents import ChatAgent\n",
    "from camel.extractors import BaseExtractor, BoxedStrategy\n",
    "\n",
    "# Initialize extractor\n",
    "extractor = BaseExtractor([[BoxedStrategy()]])\n",
    "await extractor.setup()\n",
    "agent = ChatAgent(model=model)\n",
    "\n",
    "SYSTEM_PROMPT = r\"\"\"\n",
    "You are an agent designed to answer mathematical questions with clarity and precision. Your task is to provide a step-by-step explanation for \n",
    "any mathematical problem posed by the user, ensuring the response is easy to follow. Adhere to these guidelines:\n",
    "Analyze the mathematical question carefully and break down the solution process into clear, logical steps.\n",
    "Use natural language to explain each step, incorporating LaTeX notation (e.g., $x + 2$) \n",
    "for mathematical expressions when helpful. Conclude your response with the final answer enclosed \n",
    "in a LaTeX \\boxed{} environment (e.g., \\boxed{5}). \n",
    "Place this at the end of your explanation as a standalone statement.\n",
    "\n",
    "The question you should answer is: \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's compare the agents output to our pseudo ground truth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.step(SYSTEM_PROMPT + obs.question)\n",
    "\n",
    "proposed_solution = await extractor.extract(response.msgs[0].content)\n",
    "\n",
    "result = await env.step(Action(index=0, llm_response=proposed_solution))\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
